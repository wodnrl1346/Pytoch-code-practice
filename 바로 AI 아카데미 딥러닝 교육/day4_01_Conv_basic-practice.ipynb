{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter 는 어떻게 선언하는 걸까? (feat. Conv2d)\n",
    "### Convolutional Filter 와 친해지는 시간을 가져보자!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv2d (input channel, output channel, kernel_size, stride, padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(input_ch = 1, output_ch = 1, kernel_size = 3) ☞ input channel 1 (= 흑백 img), output chennel 도 1, kernel size = 3 \\* 3<br>\n",
    "만약 kernel_size = (3,1) 이라면? ☞ 3 \\* 1 짜리 커널을 일컫는다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Example : Convolutional Layer 선언하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input channel 이 1, output channel 이 12, kernel size 가 2 * 2 짜리 Conv layer 는 어떻게 만들까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 12, kernel_size=(2, 2), stride=(1, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(1,12,2)\n",
    "conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 input channel 이 3, output channel 이 5, kernel size 가 11, stride 가 4, padding 1 은 어떻게 만들죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 5, kernel_size=(11, 11), stride=(4, 4), padding=(1, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3, 5, 11, stride = 4, padding = 1)\n",
    "conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 이제는 실제로 data 를 Conv Layer 에 넣어보고 output 을 관찰해봅시다!\n",
    "### - Kernel size, stride, padding 을 이용해서 output data의 shape 를 계산하려면?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$shape = \\displaystyle \\frac{(Input shape) - (kernel size)+ 2*(padding)}{stride} + 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex)\n",
    " - input data shape = 57, 57\n",
    " - Kernel size = (3,3)\n",
    " - stride = 2\n",
    " - padding = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$shape = \\displaystyle \\frac{(57,57) - (3)+ 2*(0)}{2} + 1= \\displaystyle \\frac{(54,54)}{2} + 1= \\displaystyle {(27,27)} + 1= \\displaystyle {(28,28)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실제로 해보자 (예제 1)<br>\n",
    " - H = 57, W = 57 짜리 input 을 선언 (data 갯수 1, channel 3 이라 가정)\n",
    " - Output channel 은 32\n",
    " - Con Layer는 아까와 마찬가지로 kernel size 가 3, stride 가 2, padding 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. data 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 57, 57])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = torch.Tensor(1, 3, 57, 57) #1=batch_size, 3 input channel, (57,57) shape\n",
    "input_size.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Convolutional Layer 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3, 32, 3, stride =2, padding =0)\n",
    "conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 Convolutional Layer 에 통과시켜보자<br>\n",
    "Conv2d(3, 1, kernel_size=(3, 3), stride=(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### → output channel 32 그리고 28 * 28 의 output 을 얻었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = conv(input_size)\n",
    "out.shape\n",
    "\n",
    "# 여기서 55,55 는 어떻게 계산되었을까?\n",
    "# (57 - 3 + 2*padding) / 2 + 1 = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz) 예시를 통해서 스스로 계산해보기 (data 의 갯수는 전부  1개)\n",
    " - Practice 1<br>input shape ☞ 128, 128  <br>Conv layer ☞ kernel size=5* 5 stride=2, padding=1 <br> input channel 3 <br> output channel 32<br><br> \n",
    " - Practice 2<br>input shape ☞ 224, 224<br>Conv layer ☞ kernel size=7* 7 stride=4, padding=0 <br> input channel 64 <br> output channel 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Practice1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 63, 63])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = torch.Tensor(1, 3, 128, 128)\n",
    "conv = nn.Conv2d(3, 32, 5, 2, 1)\n",
    "out = conv(input_size)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.Tensor(1, 64, 224, 224)\n",
    "conv_layer = nn.Conv2d(64, 128, 7, 4, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 55, 55])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = conv_layer(input_data)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자꾸 나누어 떨어지지 '않는' 것만 하니까 뭔가 아쉽다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input shape ☞ 40, 40 <br>\n",
    "Conv layer ☞ kernel size=4* 4 stride=4, padding=4 <br>\n",
    "input channel 4 <br> output channel 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.Tensor(1, 4, 40, 40)\n",
    "conv = nn.Conv2d(4, 4, 4, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = conv(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 12, 12])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
