{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - Ⅱ\n",
    "-미국 보스턴 지역의 집값을 13개의 Feature를 이용하여 예측하는 모델을 만들어 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Data\n",
    "-Bostion Housing 데이터셋\n",
    "-보스턴 지역의 주변 환경에 대한 수치값과 집값 데이터\n",
    "- Sample수 : 506개\n",
    "- Feature : 14개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('./BostonHousing.csv') #csv(comma-separated values)파일 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     ptratio   black  lstat  medv  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_raw.shape) # Dataset의 크기 확인\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "# X값 coulumn\n",
    "x = df_raw.drop(['medv'], axis=1)\n",
    "\n",
    "# y값 column\n",
    "y = df_raw['medv']\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train의 크기:  (354, 13)\n",
      "y_train의 크기:  (354,) \n",
      "\n",
      "x_test의 크기:  (152, 13)\n",
      "y_test의 크기:  (152,)\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#학습데이터와 테스트데이터를 일정비율로 나누기\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1234)\n",
    "\n",
    "#학습 데이터\n",
    "print(\"x_train의 크기: \",x_train.shape)\n",
    "print(\"y_train의 크기: \",y_train.shape,'\\n')\n",
    "\n",
    "#테스트 데이터 \n",
    "print(\"x_test의 크기: \",x_test.shape)\n",
    "print(\"y_test의 크기: \",y_test.shape)\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 데이터 Scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scale =  scaler.transform(x_train)  # x_train_scale은 numpy ndarray \n",
    "\n",
    "\n",
    "#테스트 데이터 Scaling\n",
    "x_test_scale = scaler.transform(x_test)    # x_test_scale은 numpy ndarray \n",
    "\n",
    "\n",
    "# Array-->Tensor\n",
    "x_train_tensor = torch.FloatTensor(x_train_scale)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values) #판다스 Series이므로 values를 사용해서 numpy ndarray로 가져오기\n",
    "\n",
    "x_test_tensor = torch.FloatTensor(x_test_scale)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([100, 13])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "#학습 데이터 배치화 시키기 \n",
    "train_data =  data_utils.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "\n",
    "dataloader =  data_utils.DataLoader(train_data, batch_size=100, shuffle=True, drop_last=True)\n",
    "\n",
    "#배치화된 데이터 확인\n",
    "for batch_idx, datas in enumerate(dataloader):\n",
    "    \n",
    "    print(batch_idx)\n",
    "    print(datas[0].shape)  # x_train \n",
    "    print(datas[1].shape) # y_train\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter 정의\n",
    "input_size = 13\n",
    "output_size = 1\n",
    "learning_rate = 0.1\n",
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 생성\n",
    "model = torch.nn.Linear(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#손실함수 생성\n",
    "criterion = torch.nn.MSELoss()\n",
    "#Optimizer 생성\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3]Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, Loss_train:276.82, Loss_test:169.24\n",
      "epoch:1, Loss_train:81.87, Loss_test:59.04\n",
      "epoch:2, Loss_train:43.77, Loss_test:33.72\n",
      "epoch:3, Loss_train:45.14, Loss_test:25.43\n",
      "epoch:4, Loss_train:24.12, Loss_test:22.52\n",
      "epoch:5, Loss_train:25.07, Loss_test:21.86\n",
      "epoch:6, Loss_train:29.02, Loss_test:24.21\n",
      "epoch:7, Loss_train:14.57, Loss_test:22.79\n",
      "epoch:8, Loss_train:32.83, Loss_test:23.03\n",
      "epoch:9, Loss_train:19.51, Loss_test:22.24\n",
      "epoch:10, Loss_train:25.27, Loss_test:22.09\n",
      "epoch:11, Loss_train:39.36, Loss_test:24.71\n",
      "epoch:12, Loss_train:21.85, Loss_test:23.94\n",
      "epoch:13, Loss_train:19.43, Loss_test:23.15\n",
      "epoch:14, Loss_train:26.24, Loss_test:23.45\n",
      "epoch:15, Loss_train:31.77, Loss_test:23.56\n",
      "epoch:16, Loss_train:21.04, Loss_test:23.14\n",
      "epoch:17, Loss_train:22.26, Loss_test:22.81\n",
      "epoch:18, Loss_train:21.38, Loss_test:24.74\n",
      "epoch:19, Loss_train:25.41, Loss_test:23.48\n",
      "epoch:20, Loss_train:26.93, Loss_test:24.89\n",
      "epoch:21, Loss_train:20.80, Loss_test:23.03\n",
      "epoch:22, Loss_train:18.80, Loss_test:24.43\n",
      "epoch:23, Loss_train:21.60, Loss_test:23.53\n",
      "epoch:24, Loss_train:22.20, Loss_test:23.69\n",
      "epoch:25, Loss_train:13.10, Loss_test:23.28\n",
      "epoch:26, Loss_train:31.22, Loss_test:23.70\n",
      "epoch:27, Loss_train:18.26, Loss_test:24.34\n",
      "epoch:28, Loss_train:33.67, Loss_test:23.69\n",
      "epoch:29, Loss_train:23.22, Loss_test:24.14\n",
      "epoch:30, Loss_train:33.45, Loss_test:25.50\n",
      "epoch:31, Loss_train:22.56, Loss_test:23.96\n",
      "epoch:32, Loss_train:22.24, Loss_test:24.49\n",
      "epoch:33, Loss_train:15.51, Loss_test:23.76\n",
      "epoch:34, Loss_train:22.46, Loss_test:23.71\n",
      "epoch:35, Loss_train:17.88, Loss_test:25.05\n",
      "epoch:36, Loss_train:24.05, Loss_test:24.71\n",
      "epoch:37, Loss_train:25.35, Loss_test:23.69\n",
      "epoch:38, Loss_train:19.16, Loss_test:24.97\n",
      "epoch:39, Loss_train:24.38, Loss_test:26.82\n",
      "epoch:40, Loss_train:30.14, Loss_test:25.34\n",
      "epoch:41, Loss_train:24.55, Loss_test:23.72\n",
      "epoch:42, Loss_train:19.09, Loss_test:25.08\n",
      "epoch:43, Loss_train:17.29, Loss_test:24.09\n",
      "epoch:44, Loss_train:32.13, Loss_test:27.00\n",
      "epoch:45, Loss_train:20.29, Loss_test:24.84\n",
      "epoch:46, Loss_train:28.86, Loss_test:24.50\n",
      "epoch:47, Loss_train:16.73, Loss_test:24.51\n",
      "epoch:48, Loss_train:26.84, Loss_test:23.97\n",
      "epoch:49, Loss_train:26.14, Loss_test:24.64\n",
      "epoch:50, Loss_train:25.79, Loss_test:24.55\n",
      "epoch:51, Loss_train:18.31, Loss_test:24.03\n",
      "epoch:52, Loss_train:29.19, Loss_test:24.81\n",
      "epoch:53, Loss_train:17.54, Loss_test:23.80\n",
      "epoch:54, Loss_train:20.64, Loss_test:23.63\n",
      "epoch:55, Loss_train:14.76, Loss_test:23.71\n",
      "epoch:56, Loss_train:24.73, Loss_test:24.06\n",
      "epoch:57, Loss_train:18.35, Loss_test:23.64\n",
      "epoch:58, Loss_train:22.52, Loss_test:23.86\n",
      "epoch:59, Loss_train:29.50, Loss_test:24.14\n",
      "epoch:60, Loss_train:34.37, Loss_test:24.26\n",
      "epoch:61, Loss_train:20.25, Loss_test:24.10\n",
      "epoch:62, Loss_train:22.40, Loss_test:23.56\n",
      "epoch:63, Loss_train:21.21, Loss_test:24.17\n",
      "epoch:64, Loss_train:18.34, Loss_test:23.97\n",
      "epoch:65, Loss_train:31.39, Loss_test:23.97\n",
      "epoch:66, Loss_train:31.54, Loss_test:24.35\n",
      "epoch:67, Loss_train:24.15, Loss_test:24.23\n",
      "epoch:68, Loss_train:16.40, Loss_test:24.53\n",
      "epoch:69, Loss_train:21.88, Loss_test:24.80\n",
      "epoch:70, Loss_train:19.58, Loss_test:24.66\n",
      "epoch:71, Loss_train:17.19, Loss_test:23.61\n",
      "epoch:72, Loss_train:20.25, Loss_test:24.31\n",
      "epoch:73, Loss_train:22.92, Loss_test:24.01\n",
      "epoch:74, Loss_train:20.39, Loss_test:24.47\n",
      "epoch:75, Loss_train:16.99, Loss_test:23.53\n",
      "epoch:76, Loss_train:23.53, Loss_test:23.44\n",
      "epoch:77, Loss_train:28.02, Loss_test:24.02\n",
      "epoch:78, Loss_train:16.73, Loss_test:24.21\n",
      "epoch:79, Loss_train:20.38, Loss_test:24.19\n",
      "epoch:80, Loss_train:20.99, Loss_test:23.33\n",
      "epoch:81, Loss_train:26.20, Loss_test:28.66\n",
      "epoch:82, Loss_train:20.30, Loss_test:24.28\n",
      "epoch:83, Loss_train:18.80, Loss_test:23.42\n",
      "epoch:84, Loss_train:25.26, Loss_test:23.69\n",
      "epoch:85, Loss_train:22.43, Loss_test:24.51\n",
      "epoch:86, Loss_train:14.53, Loss_test:23.16\n",
      "epoch:87, Loss_train:28.51, Loss_test:23.25\n",
      "epoch:88, Loss_train:20.05, Loss_test:24.16\n",
      "epoch:89, Loss_train:15.38, Loss_test:23.78\n",
      "epoch:90, Loss_train:17.69, Loss_test:25.35\n",
      "epoch:91, Loss_train:15.68, Loss_test:23.28\n",
      "epoch:92, Loss_train:28.25, Loss_test:23.33\n",
      "epoch:93, Loss_train:18.74, Loss_test:23.39\n",
      "epoch:94, Loss_train:13.64, Loss_test:23.55\n",
      "epoch:95, Loss_train:18.45, Loss_test:23.75\n",
      "epoch:96, Loss_train:18.12, Loss_test:23.88\n",
      "epoch:97, Loss_train:35.32, Loss_test:26.72\n",
      "epoch:98, Loss_train:28.64, Loss_test:28.56\n",
      "epoch:99, Loss_train:34.50, Loss_test:24.50\n",
      "epoch:100, Loss_train:19.89, Loss_test:24.19\n",
      "epoch:101, Loss_train:21.95, Loss_test:23.61\n",
      "epoch:102, Loss_train:23.27, Loss_test:23.55\n",
      "epoch:103, Loss_train:15.86, Loss_test:23.74\n",
      "epoch:104, Loss_train:34.35, Loss_test:25.43\n",
      "epoch:105, Loss_train:13.48, Loss_test:23.93\n",
      "epoch:106, Loss_train:26.27, Loss_test:23.52\n",
      "epoch:107, Loss_train:19.68, Loss_test:24.82\n",
      "epoch:108, Loss_train:25.47, Loss_test:24.39\n",
      "epoch:109, Loss_train:21.91, Loss_test:24.93\n",
      "epoch:110, Loss_train:23.03, Loss_test:24.14\n",
      "epoch:111, Loss_train:23.66, Loss_test:23.85\n",
      "epoch:112, Loss_train:21.98, Loss_test:24.11\n",
      "epoch:113, Loss_train:24.17, Loss_test:24.16\n",
      "epoch:114, Loss_train:14.34, Loss_test:24.46\n",
      "epoch:115, Loss_train:19.89, Loss_test:25.45\n",
      "epoch:116, Loss_train:24.48, Loss_test:27.85\n",
      "epoch:117, Loss_train:13.60, Loss_test:24.04\n",
      "epoch:118, Loss_train:24.73, Loss_test:24.19\n",
      "epoch:119, Loss_train:17.07, Loss_test:24.07\n",
      "epoch:120, Loss_train:18.80, Loss_test:24.19\n",
      "epoch:121, Loss_train:28.16, Loss_test:24.52\n",
      "epoch:122, Loss_train:33.76, Loss_test:24.86\n",
      "epoch:123, Loss_train:22.56, Loss_test:23.94\n",
      "epoch:124, Loss_train:31.75, Loss_test:23.96\n",
      "epoch:125, Loss_train:25.45, Loss_test:25.33\n",
      "epoch:126, Loss_train:25.56, Loss_test:24.36\n",
      "epoch:127, Loss_train:16.50, Loss_test:25.94\n",
      "epoch:128, Loss_train:27.04, Loss_test:24.77\n",
      "epoch:129, Loss_train:16.69, Loss_test:23.74\n",
      "epoch:130, Loss_train:23.70, Loss_test:25.08\n",
      "epoch:131, Loss_train:23.84, Loss_test:23.66\n",
      "epoch:132, Loss_train:24.81, Loss_test:24.18\n",
      "epoch:133, Loss_train:21.69, Loss_test:23.54\n",
      "epoch:134, Loss_train:21.05, Loss_test:23.18\n",
      "epoch:135, Loss_train:27.18, Loss_test:23.60\n",
      "epoch:136, Loss_train:26.76, Loss_test:23.84\n",
      "epoch:137, Loss_train:26.29, Loss_test:23.63\n",
      "epoch:138, Loss_train:27.75, Loss_test:25.62\n",
      "epoch:139, Loss_train:17.07, Loss_test:23.90\n",
      "epoch:140, Loss_train:26.60, Loss_test:24.26\n",
      "epoch:141, Loss_train:27.78, Loss_test:24.48\n",
      "epoch:142, Loss_train:31.01, Loss_test:23.81\n",
      "epoch:143, Loss_train:17.15, Loss_test:23.95\n",
      "epoch:144, Loss_train:27.42, Loss_test:23.59\n",
      "epoch:145, Loss_train:22.06, Loss_test:23.67\n",
      "epoch:146, Loss_train:27.81, Loss_test:23.99\n",
      "epoch:147, Loss_train:15.85, Loss_test:23.51\n",
      "epoch:148, Loss_train:26.97, Loss_test:23.61\n",
      "epoch:149, Loss_train:29.84, Loss_test:26.69\n",
      "epoch:150, Loss_train:17.45, Loss_test:25.26\n",
      "epoch:151, Loss_train:23.25, Loss_test:24.41\n",
      "epoch:152, Loss_train:26.12, Loss_test:26.74\n",
      "epoch:153, Loss_train:21.83, Loss_test:24.28\n",
      "epoch:154, Loss_train:31.24, Loss_test:24.68\n",
      "epoch:155, Loss_train:19.89, Loss_test:24.54\n",
      "epoch:156, Loss_train:20.22, Loss_test:24.32\n",
      "epoch:157, Loss_train:28.61, Loss_test:23.91\n",
      "epoch:158, Loss_train:21.61, Loss_test:24.28\n",
      "epoch:159, Loss_train:18.38, Loss_test:24.40\n",
      "epoch:160, Loss_train:21.88, Loss_test:24.12\n",
      "epoch:161, Loss_train:27.68, Loss_test:24.89\n",
      "epoch:162, Loss_train:16.34, Loss_test:25.05\n",
      "epoch:163, Loss_train:17.01, Loss_test:25.07\n",
      "epoch:164, Loss_train:18.47, Loss_test:24.26\n",
      "epoch:165, Loss_train:17.02, Loss_test:24.95\n",
      "epoch:166, Loss_train:21.59, Loss_test:24.61\n",
      "epoch:167, Loss_train:25.10, Loss_test:24.60\n",
      "epoch:168, Loss_train:22.57, Loss_test:24.10\n",
      "epoch:169, Loss_train:26.11, Loss_test:24.79\n",
      "epoch:170, Loss_train:23.23, Loss_test:24.57\n",
      "epoch:171, Loss_train:26.92, Loss_test:25.26\n",
      "epoch:172, Loss_train:25.45, Loss_test:24.94\n",
      "epoch:173, Loss_train:29.60, Loss_test:25.22\n",
      "epoch:174, Loss_train:18.15, Loss_test:25.49\n",
      "epoch:175, Loss_train:20.27, Loss_test:24.44\n",
      "epoch:176, Loss_train:14.05, Loss_test:24.35\n",
      "epoch:177, Loss_train:17.73, Loss_test:24.25\n",
      "epoch:178, Loss_train:22.11, Loss_test:24.10\n",
      "epoch:179, Loss_train:29.35, Loss_test:26.55\n",
      "epoch:180, Loss_train:25.26, Loss_test:25.53\n",
      "epoch:181, Loss_train:28.36, Loss_test:26.73\n",
      "epoch:182, Loss_train:30.96, Loss_test:25.97\n",
      "epoch:183, Loss_train:24.05, Loss_test:24.73\n",
      "epoch:184, Loss_train:26.83, Loss_test:24.69\n",
      "epoch:185, Loss_train:22.33, Loss_test:24.41\n",
      "epoch:186, Loss_train:21.48, Loss_test:25.34\n",
      "epoch:187, Loss_train:18.92, Loss_test:24.38\n",
      "epoch:188, Loss_train:18.66, Loss_test:24.49\n",
      "epoch:189, Loss_train:27.15, Loss_test:24.23\n",
      "epoch:190, Loss_train:24.78, Loss_test:24.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:191, Loss_train:31.63, Loss_test:25.67\n",
      "epoch:192, Loss_train:34.11, Loss_test:24.55\n",
      "epoch:193, Loss_train:27.90, Loss_test:23.98\n",
      "epoch:194, Loss_train:21.43, Loss_test:24.07\n",
      "epoch:195, Loss_train:19.68, Loss_test:23.60\n",
      "epoch:196, Loss_train:33.60, Loss_test:26.14\n",
      "epoch:197, Loss_train:25.58, Loss_test:24.97\n",
      "epoch:198, Loss_train:17.42, Loss_test:23.80\n",
      "epoch:199, Loss_train:21.19, Loss_test:23.83\n",
      "epoch:200, Loss_train:16.91, Loss_test:24.30\n"
     ]
    }
   ],
   "source": [
    "## Running the model\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "for epoch in range(n_epochs+1):\n",
    "    \n",
    "    for idx, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        \n",
    "        #Batch 학습\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(x_batch)\n",
    "        y_pred = y_pred.reshape(-1)\n",
    "        \n",
    "        loss_train = criterion(y_pred, y_batch)\n",
    "        \n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        #Validation\n",
    "        model.eval()\n",
    "        y_test_pred = model(x_test_tensor)\n",
    "        \n",
    "        y_test_pred = y_test_pred.reshape(-1)\n",
    "        \n",
    "        loss_test = criterion(y_test_pred, y_test_tensor)\n",
    "        \n",
    "        \n",
    "        \n",
    "   \n",
    "    train_loss.append(loss_train.item())\n",
    "    test_loss.append(loss_test.item())\n",
    "    print(\"epoch:{}, Loss_train:{:.2f}, Loss_test:{:.2f}\".format( epoch, train_loss[-1], test_loss[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss 값 plot\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(test_loss, label='test')\n",
    "plt.title('Model loss')\n",
    "plt.legend(loc= 'upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <Scaling>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tip) Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ x_in = \\frac{x_io - \\mu_i}{\\sigma_i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "[0.5 4. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.25"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = [[0, 0], [0, 0], [1, 8], [1, 8]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "data_arr= np.array(data)\n",
    "\n",
    "print(data_arr.shape)\n",
    "print(np.mean(data_arr, axis= 0))\n",
    "data_arr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.],\n",
       "       [-1., -1.],\n",
       "       [ 1.,  1.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_arr_scaler=scaler.transform(data_arr)\n",
    "data_arr_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.transform([[2, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_arr_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(data_arr_scaler, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr_scaler.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr_scaler.std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
