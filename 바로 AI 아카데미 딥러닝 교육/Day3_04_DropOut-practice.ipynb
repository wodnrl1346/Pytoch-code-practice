{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class model with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning message 제거\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# loss 값 ploting 을 위해 사용\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check GPU and fix the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train 의 shape=(60000, 784), y_train 의 shape=(60000,)\n",
      "x_test 의 shape=(10000, 784), y_test 의 shape=(10000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = MNIST('./MNIST')\n",
    "mnist.gz = True\n",
    "x_train, y_train = mnist.load_training()\n",
    "x_test, y_test = mnist.load_testing()\n",
    "\n",
    "# data 는 list 형식을 되어 있으므로 shape 을 보고, 이미지 visualization 을 하기 편한 array 형태로 바꾸어준다.\n",
    "\n",
    "x_train=np.asarray(x_train)\n",
    "y_train=np.asarray(y_train)\n",
    "x_test=np.asarray(x_test)\n",
    "y_test=np.asarray(y_test)\n",
    "\n",
    "print(\"x_train 의 shape={}, y_train 의 shape={}\".format(x_train.shape,y_train.shape))\n",
    "print(\"x_test 의 shape={}, y_test 의 shape={}\".format(x_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dataset into Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "traindata = data_utils.TensorDataset(torch.FloatTensor(x_train), torch.FloatTensor(y_train))\n",
    "trainloader = data_utils.DataLoader(traindata, batch_size = batch_size ,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p – probability of an element to be zeroed. Default: 0.5 => 0으로 만들어줄 확률, 쉬운 이해를 위해 아래 예시를 참조\n",
    "drop_prob1 = 0.4 # 40%는 out\n",
    "drop_prob2 = 0.25 # 25%는 out\n",
    "\n",
    "class Dropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Dropout, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "        self.dp1 = nn.Dropout(p = drop_prob1)\n",
    "        self.dp2 = nn.Dropout(p = drop_prob2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        h1dp = self.dp1(h1)\n",
    "        \n",
    "        h2 = F.relu(self.fc2(h1dp))\n",
    "        h2dp = self.dp2(h2)\n",
    "        \n",
    "        output = self.fc3(h2dp)\n",
    "            \n",
    "        return output\n",
    "\n",
    "model = Dropout().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dropout(\n",
       "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (dp1): Dropout(p=0.4, inplace=False)\n",
       "  (dp2): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 15\n",
    "learning_rate = 0.01\n",
    "weight_decay = 1e-5\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1\tAverage loss = 7.05315877199173\n",
      "Epoch = 2\tAverage loss = 2.022984604040782\n",
      "Epoch = 3\tAverage loss = 1.7004256685574852\n",
      "Epoch = 4\tAverage loss = 1.2707194805145263\n",
      "Epoch = 5\tAverage loss = 0.9756577442089719\n",
      "Epoch = 6\tAverage loss = 0.826453431447347\n",
      "Epoch = 7\tAverage loss = 0.726645968357722\n",
      "Epoch = 8\tAverage loss = 0.6483511755863824\n",
      "Epoch = 9\tAverage loss = 0.5848774055639903\n",
      "Epoch = 10\tAverage loss = 0.5330233708024025\n",
      "Epoch = 11\tAverage loss = 0.5016288777192434\n",
      "Epoch = 12\tAverage loss = 0.48526539603869123\n",
      "Epoch = 13\tAverage loss = 0.4657049253582954\n",
      "Epoch = 14\tAverage loss = 0.46473103215297074\n",
      "Epoch = 15\tAverage loss = 0.45490695983171464\n"
     ]
    }
   ],
   "source": [
    "# model = Dropout().to(device)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "for epoch_num in range(epoch):\n",
    "    model.train()\n",
    "    average_loss = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(trainloader):\n",
    "        num_of_mini_batch = len(trainloader)\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predicted = model(images)\n",
    "        \n",
    "        labels_long = torch.tensor(labels, dtype = torch.long)\n",
    "        labels_long = labels_long.to(device)\n",
    "        \n",
    "        loss = loss_function(predicted, labels_long)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        average_loss += (loss.item()/num_of_mini_batch)\n",
    "   \n",
    "    print(\"Epoch = {}\\tAverage loss = {}\".format((epoch_num+1), average_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 3rd Epoch average Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.700425668557485\n"
     ]
    }
   ],
   "source": [
    "epoch_loss = 0\n",
    "for i in range(60):\n",
    "    epoch_loss = epoch_loss + loss_list[i+120]\n",
    "    \n",
    "print(epoch_loss/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_list의 길이 = 900\n"
     ]
    }
   ],
   "source": [
    "# 60000개를 1000 배치로 나누었을때 60이 되므로 epoch 하나당 60 묶음의 배치가 학습이된다\n",
    "# 15 epoch 이므로 900 묶음의 배치가 학습이 되게 되고 list 에 append 되는 loss value 도 900 개가 된다.\n",
    "print(\"loss_list의 길이 =\",len(loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23.805875778198242,\n",
       " 146.95936584472656,\n",
       " 76.81898498535156,\n",
       " 35.470550537109375,\n",
       " 14.43237018585205,\n",
       " 5.475516319274902,\n",
       " 3.118227481842041,\n",
       " 2.625511407852173,\n",
       " 2.4763846397399902,\n",
       " 2.33309268951416]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12e810d6550>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(loss_list[7:]), 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# wb - 바이트 형식으로 저장\n",
    "\n",
    "with open('Dropout.pickle', 'wb') as f:\n",
    "    pickle.dump(loss_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data_utils.TensorDataset(torch.FloatTensor(x_test), torch.FloatTensor(y_test))\n",
    "\n",
    "testloader = data_utils.DataLoader(test_data, batch_size = 5000, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 2.00 GiB total capacity; 25.89 MiB already allocated; 0 bytes free; 30.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 10\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m output_sftmax \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(output) \u001b[38;5;66;03m# torch.nn.functional.softmax = F.softmax\u001b[39;00m\n\u001b[0;32m     13\u001b[0m predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(output_sftmax, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 17\u001b[0m     h1 \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     h1dp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdp1(h1)\n\u001b[0;32m     20\u001b[0m     h2 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(h1dp))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deep\\lib\\site-packages\\torch\\nn\\functional.py:1442\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1440\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1442\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 2.00 GiB total capacity; 25.89 MiB already allocated; 0 bytes free; 30.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    num_total_data = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for _, (images, labels) in enumerate(testloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        output = model(images)\n",
    "        output_sftmax = F.softmax(output) # torch.nn.functional.softmax = F.softmax\n",
    "        \n",
    "        predicted = torch.argmax(output_sftmax, dim=1)\n",
    "        \n",
    "        num_total_data += len(images)\n",
    "        \n",
    "        answer = sum(labels == predicted).item()\n",
    "        correct += answer\n",
    "        \n",
    "    print(\"Dropout 을 사용한 accuracy = %.2f%%\" %((correct/num_total_data)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_prob1 = 0.5\n",
    "# drop_prob2 = 0.3 으로 설정해놓고 다시 돌려보자"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
