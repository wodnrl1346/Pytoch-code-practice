{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문자열 데이터로 RNN 학습하기\n",
    "-문자열 데이터를 벡터로 표현하기 위해 원핫인코딩(One-Hot Encoding)을 사용한다.  \n",
    "-원핫인코딩으로 표현한 데이터를 가지고 RNN을 학습한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Data Preprocessing\n",
    "- 단어 'tomato'를 철자 단위에서 학습을 시켜보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'o', 'm', 'a', 't', 'o']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'tomato'\n",
    "string = list(string)\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'm', 'o', 't'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_string = set(string)           # 중복을 허용하지 않는 데이터 타입 set\n",
    "set_string               # tomato 단어는 t, o, m, a로 구성되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_string = ['t', 'o', 'm', 'a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- str데이터를 원핫인코딩으로 표현한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data는 맨마지막 철자를 제외하고 입력한다\n",
    "\n",
    "encoding_X = [[[ 1, 0, 0, 0 ],   # t --> 0\n",
    "               [ 0, 1, 0, 0 ],   # o --> 1\n",
    "               [ 0, 0, 1, 0 ],   # m --> 2\n",
    "               [ 0, 0, 0, 1 ],   # a --> 3\n",
    "               [ 1, 0, 0, 0 ]]]  # t --> 0\n",
    "\n",
    "\n",
    "target = [[ 1, 2, 3, 0, 1 ]] # 처음 시작하는 철자를 제외하고 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.FloatTensor( encoding_X )\n",
    "Y = torch.LongTensor( target )\n",
    "X = X.reshape(5, 1, 4)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter \n",
    "input_size = 4  #원핫인코딩의 Dimension\n",
    "hidden_size = 4\n",
    "epoch = 20\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 선언\n",
    "model =  torch.nn.RNN(input_size, hidden_size, batch_first=True)     # batch_first --> (Batch, Seq, input_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function, optimizer 선언\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 loss:1.45 --> 예측한 문자:ttttt, 예측값:[0 0 0 0 0]\n",
      "epoch:1 loss:1.26 --> 예측한 문자:ottto, 예측값:[1 0 0 0 1]\n",
      "epoch:2 loss:1.12 --> 예측한 문자:otaoo, 예측값:[1 0 3 1 1]\n",
      "epoch:3 loss:1.03 --> 예측한 문자:ooaoo, 예측값:[1 1 3 1 1]\n",
      "epoch:4 loss:0.96 --> 예측한 문자:ooaoo, 예측값:[1 1 3 1 1]\n",
      "epoch:5 loss:0.89 --> 예측한 문자:ooaoo, 예측값:[1 1 3 1 1]\n",
      "epoch:6 loss:0.83 --> 예측한 문자:ooaoo, 예측값:[1 1 3 1 1]\n",
      "epoch:7 loss:0.75 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "epoch:8 loss:0.68 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "epoch:9 loss:0.61 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "epoch:10 loss:0.56 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "epoch:11 loss:0.52 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "epoch:12 loss:0.49 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "epoch:13 loss:0.47 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "epoch:14 loss:0.46 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "epoch:15 loss:0.45 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "epoch:16 loss:0.43 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "epoch:17 loss:0.42 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "epoch:18 loss:0.41 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "epoch:19 loss:0.40 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n",
      "epoch:20 loss:0.40 --> 예측한 문자:omato, 예측값:[1 2 3 0 1]\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "for i in range(epoch+1):\n",
    "    optimizer.zero_grad()\n",
    "    outputs, status  = model(X)\n",
    "    \n",
    "    outputs = outputs.reshape(-1, input_size)\n",
    "    Y = Y.reshape(-1)\n",
    "    \n",
    "    loss = criterion(outputs, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    result = outputs.detach().numpy().argmax(axis=1)\n",
    "    result = result.reshape(-1)\n",
    "    result_string = ''.join([set_string[s] for s in result])\n",
    "\n",
    "    print(f'epoch:{i} loss:{loss:.2f} --> 예측한 문자:{result_string}, 예측값:{result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] Test\n",
    "-임의의 원핫인코딩 텐서를 입력해서 결과를 확인해본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = torch.FloatTensor([[1, 0, 0, 0],\n",
    "                            [0, 1, 0, 0]]) # t o m a 의 원핫인코딩값\n",
    "\n",
    "test_x = test_x.reshape(2, 1, 4)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측한 문자: om, 예측값:[1 2]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_output, status = model(test_x)\n",
    "    \n",
    "    result = test_output.detach().numpy().argmax(axis=2)\n",
    "    result = result.reshape(-1)\n",
    "    result_string = ''.join([set_string[s] for s in result])\n",
    "    print(f'예측한 문자: {result_string}, 예측값:{result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
